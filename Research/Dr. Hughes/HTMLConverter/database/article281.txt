45 comments

   [700]Comments feed for this article


   [701]17 July, 2016 at 9:19 am

   [702]sylvainjulien


   Would a weakened form of Cramer’s conjecture like
   $g_{n}=\log^{O(1)}p_{n}$ be strong enough to imply the twin
   prime conjecture?
   [703]Reply
       [704]19 July, 2016 at 3:33 am
       [705]sylvainjulien
       By the way, this link may give further support to Cramer’s
       conjecture:
       -of-pinr-0n-pin-r-0n-with-r-0n-inf-r-ge-0-n-r-n?noredirect=
       1#comment3818092_1859480
       [707]Reply


   [708]17 July, 2016 at 11:43 am

   Bhupinder Singh Anand

   1. What seems to prevent a non-heuristic determination of the
   limiting behaviour of prime counting functions is that the
   usual approximations of \pi(n) for finite values of n are
   apparently derived from real-valued functions which are
   asymptotic to \pi(x) , such as \frac{x}{log_{e}x} , Li(x) and
   Riemann’s function R(x) =
   \sum_{n=1}^{\infty}\frac{\mu(n)}{(n)}li(x^{1/n}) .

   2. The degree of approximation for finite values of n is thus
   determined only heuristically, by conjecturing upon an error
   term in the asymptotic relation that can be seen to yield a
   closer approximation than others to the actual values of \pi(n)
   .

   3. Moreover, currently, conventional approaches to evaluating
   prime counting functions for finite n may also subscribe to the
   belief:

   (i) either—explicitly (see [709]here)—that whether or not a
   prime p divides an integer n is not independent of whether or
   not a prime q \neq p divides the integer n ;


   (ii) or—implicitly (since the twin-prime problem is yet
   open)—that a proof to the contrary must imply that if P(n\ is\
   a\ prime) is the probability that n is a prime, then \sum_{_{i
   = 1}}^{^{\infty}} P(i\ is\ a\ prime) = 1 .

   4. If so, then conventional approaches seem to conflate the two
   probabilities:

   (i) The probability P(a) of selecting a number that has the
   property of being prime from a given set S of numbers;

   Example 1: I have a bag containing 100 numbers in which there
   are twice as many composites as primes. What is the probability
   that the first number you blindly pick from it is a prime. This
   is the basis for setting odds in games such as roulette.

   (ii) The probability P(b) of determining a proper factor of a
   given number n .

   Example 2: I give you a 5 -digit combination lock along with a
   10 -digit number n . The lock only opens if you set the
   combination to a proper factor of n which is greater than 1 .
   What is the probability that the first combination you try will
   open the lock. This is the basis for RSA encryption, which
   provides the cryptosystem used by many banks for securing their
   communications.

   5. In case 4(i), if the precise proportion of primes to
   non-primes in S is definable, then clearly P(a) too is
   definable.

   However if S is the set N of all integers, and we cannot define
   a precise ratio of primes to composites in N , but only an
   order of magnitude such as O(\frac{1}{log_{_{e}}n}) , then
   equally obviously P(a) cannot be defined in N (see Chapter 2,
   p.9, Theorem 2.1, [710]here).


   6. In case 4(ii) it follows that P(b) = \frac{1}{\pi(\sqrt{n})}
   , since the argument can be used to show that whether or not a
   prime p divides a given integer n is independent of whether or
   not a prime q \neq p divides n .

   7. We thus have that \pi(n) \approx n.\prod_{_{i =
   1}}^{^{\pi(\sqrt{n})}}(1-\frac{1}{p_{_{i}}}) , with a binomial
   standard deviation. Hence, even though we cannot define the
   probability P(n\ is\ a\ prime) of selecting a number from the
   set N of all natural numbers that has the property of being
   prime, \prod_{_{i =
   1}}^{^{\pi(\sqrt{n})}}(1-\frac{1}{p_{_{i}}}) can be treated as
   the de facto probability that a given n is prime.

   8. Further, by considering the asymptotic density of the set of
   all integers that are not divisible by the first \pi(\sqrt {n})
   primes p_{_{1}}, p_{_{2}}, \ldots, p_{_{\pi(\sqrt {n})}} we can
   show that, for any n , the expected number of such integers in
   any interval of length (p_{_{\pi(\sqrt{ n})+1}}^{2} -
   p_{_{\pi(\sqrt n)}}^{2}) is (p_{_{\pi(\sqrt{ n})+1}}^{2} -
   p_{_{\pi(\sqrt n)}}^{2})\prod_{i = 1}^{\pi(\sqrt{n})}(1 -
   \frac{1}{p_{_{i}}}) .

   9. We can then show that a non-heuristic approximation—with a
   binomial standard deviation—for the number of primes less than
   or equal to n is given for all n by \pi(n) \approx \sum_{j =
   1}^{n}\prod_{i = 1}^{\pi(\sqrt{j})}(1 - \frac{1}{p_{_{i}}})
   \sim a.\frac{n}{log_{e}n} \rightarrow \infty for some constant
   a > 2.e^{-\gamma} \approx 1.12292 \ldots .

   10. We can show, similarly, that the expected number of
   Dirichlet and twin primes in the interval ( p_{_{\pi(\sqrt
   {n})}}^{2},\ p_{_{\pi(\sqrt{ n})+1}}^{2} ) can be estimated
   similarly; and conclude that the number of such primes \leq n
   is, in each case, cumulatively approximated non-heuristically
   by a function that \rightarrow \infty .

   11. The method can, moreover, be generalised to apply to a
   large class of prime counting functions.
   [711]Reply
       [712]2 August, 2016 at 2:46 pm
       [713]primework123
       FYI: The Riemann Prime-Counting involving the zeta zeros of
       the Riemann zeta function is the real deal at determining
       the distribution of primes (number and placement) along the
       natural number line.
       Please visiting the following links for all reasons and
       details:
       icient_way_of_predicting_prime_numbers_accurately
       proof_of_the_famous_and_important_Polignac_Conjecture
       [716]Reply


   [717]18 July, 2016 at 4:56 am

   Zak

   Breaking the parity barrier has usually been the consequence of
   controlling bilinear sums, done for instance in Friedlander and
   Iwaniec’s work on primes of the form x^2 + y^4 . From the view
   point that sieve theory is a linear programming problem, I
   wonder if one could impose additional linear constraints in
   order to overcome the parity problem. For instance we could
   impose the condition \langle a_n , \lambda(n) \rangle_{n \leq
   x} is small, where \lambda is the Louisville function.
   [718]Reply


   [719]18 July, 2016 at 8:17 am

   Jhon Manugal

   Do you have this

   $ \sum_{n < x; d n} \Lambda(n+2) \approx \frac{g(d)}{d}x =
   x\prod_{p|d} (1 - \frac{1}{p}) $

   and also this? I don't know enough to correct you

   $ \sum_{n < x; d n} \Lambda(n+2) \approx \frac{g(d)}{d}x \,
   \log \frac{x}{d} $
   [720]Reply
       [721]18 July, 2016 at 12:08 pm
       Lior Silberman
       In the second equation, the summand is missing a factor of
       \log\frac{n}{d}
       [722]Reply


   [723]18 July, 2016 at 8:42 am

   Anonymous

   Dear Terry,
   Happy birthday to you
   But the great birthday present is that you solve twin prime
   conjecture as I expect.That is also a gift for all
   mathematicians.Time goes by quickly.It never waits everyone.A
   human becomes older very fast if without doing great thing.
   [724]Reply


   [725]18 July, 2016 at 1:21 pm

   Anonymous

   It is still not clear from this post what seems to be the most
   promising approach for a new advance in the twin prime
   conjecture. Is a breakthrough in the parity problem really
   necessary?
   [726]Reply
       [727]18 July, 2016 at 4:34 pm
       [728]Terence Tao
       Well, the twin prime sum \sum_{n \leq x} \Lambda(n)
       \Lambda(n+2) is certainly parity sensitive (viewing one of
       the factors as the sequence to be sieved and the other
       factor as the sieve), so any nontrivial estimate on it has
       to break the parity barrier one way or another, and this to
       my mind is one of the major reasons why progress on the
       twin prime conjecture will be interesting (though of course
       the accessibility and history of the conjecture is also
       appealing). It is not quite the weakest point in the parity
       barrier to breach though – given the recent advances on the
       Chowla conjecture, I would imagine that that will fall
       first before the twin prime conjecture does, since one has
       the additional tool of multiplicativity at small primes at
       one’s disposal in that case. Since (as discussed in the
       post above) the twin prime conjecture is basically
       equivalent (on GEH) to Chowla restricted to almost twin
       primes, one can hope to approach the twin prime conjecture
       by first proving Chowla, and then somehow removing, or at
       least greatly reducing, the reliance on multiplicativity at
       small prime in that proof. We already have the Chowla
       conjecture in the log-averaged setting, but that proof is
       currently extremely reliant on this multiplicativity, but
       perhaps there will be other proofs in the future that are
       less reliant.
       It may also be possible that the twin prime conjecture
       could be proven by non-analytic means, in a way that does
       not lead to significantly new estimates on the sum \sum_{n
       \leq x} \Lambda(n) \Lambda(n+2) (though this sum will of
       course have to go to infinity as x \to \infty if the twin
       prime conjecture holds). This is currently the situation in
       the function field setting, where results of Hall and of
       Pollack show that there are infinitely many twin
       irreducible polynomials over any given field of odd order;
       this relies on some criteria for polynomial irreducibility
       that are only available to a very sparse set of
       polynomials, and which are not expected to have analogues
       in the integer setting. Nevertheless the parity barrier in
       the function field setting is still very much in effect,
       and the situation there is not that much better actually
       than in the integer case (except in the large q limit,
       where much more is known).
       [729]Reply


       [730]18 July, 2016 at 8:05 pm
       Bhupinder Singh Anand
       1. Yes, instead of estimating \sum_{_{n \leq
       x}}\Lambda(n)\Lambda(n+2) heuristically by analytic
       considerations, one could also estimate the number
       \pi_{_{2}}(x) of twin primes \leq x non-heuristically as
       \sum_{_{n \leq x}}P(n).P(n+2) , where P(n) is the de facto
       probability that a given n is prime.
       2. One way of approaching this would be to define an
       integer n as a \mathbb{TW}(k) integer if, and only if,
       r_{p_{_{i}}}(n) \neq 0 and r_{p_{_{i}}}(n) \neq 2 for all 1
       \leq i \leq k , where 0 \leq r_{_{i}}(n) \leq i-1 is
       defined for all i \geq 0 by:
       n + r_{_{i}}(n) \equiv 0\ (mod\ i) .
       3. Note that if n is a \mathbb{TW}(k) integer, then both n
       and n+2 are not divisible by any of the first k primes
       \{p_{_{1}}, p_{_{2}}, \ldots, p_{_{k}}\} .
       4. The asymptotic density of \mathbb{TW}(k) integers over
       the set of natural numbers is then
       \mathbb{D}(\mathbb{TW}(k)) = \prod_{i=2}^{k}(1 -
       \frac{2}{p_{_{i}}}) .
       5. Further, if p_{_{k}}^{2} \leq n \leq p_{_{k+1}}^{2} is a
       \mathbb{TW}(k) integer, then n is a prime and either n+2 is
       also a prime, or n+2 = p_{_{k +1}}^{2} .
       6. If we define \pi_{_{\mathbb{TW}(k)}}(n) as the number of
       \mathbb{TW}(k) integers \leq n , the expected number of
       \mathbb{TW}(k) integers in any interval (a, b) is
       given—with a binomial standard deviation—by
       \pi_{_{\mathbb{TW}(k)}}(b) - \pi_{_{\mathbb{TW}(k)}}(a)
       \approx (b-a)\prod_{i=2}^{k}(1 - \frac{2}{p_{_{i}}}) .
       7. Since \pi_{_{\mathbb{TW}(k)}}(p_{_{k+1}}^{2}) -
       \pi_{_{\mathbb{TW}(k)}}(p_{_{k}}^{2}) is at most one less
       than the number of twin-primes in the interval
       (p_{_{k+1}}^{2} - p_{_{k}}^{2}) , it follows that:
       \pi_{_{\mathbb{TW}(k)}}(p_{_{k+1}}^{2}) -
       \pi_{_{\mathbb{TW}(k)}}(p_{_{k}}^{2}) + 1 \geq
       \pi_{_{2}}(p_{_{k+1}}^{2}) - \pi_{_{2}}(p_{_{k)}}^{2}) \geq
       \pi_{_{\mathbb{TW}(k)}}(p_{_{k+1}}^{2}) -
       \pi_{_{\mathbb{TW}(k)}}(p_{_{k}}^{2})
       8. Now, the expected number of \mathbb{TW}(k) integers in
       the interval (p_{_{k+1}}^{2} - p_{_{k}}^{2}) is given by:
       \pi_{_{\mathbb{TW}(k)}}(p_{_{k+1}}^{2}) -
       \pi_{_{\mathbb{TW}(k)}}(p_{_{k}}^{2}) \approx
       (p_{_{k+1}}^{2} - p_{_{k}}^{2})\prod_{i=2}^{k}(1 -
       \frac{2}{p_{_{i}}}) .
       9. We conclude that the number \pi_{_{2}} of twin primes
       \leq p_{_{k+1}}^{2} is given by the cumulative
       non-heuristic approximation:
       \sum_{j=1}^{k} (\pi_{_{2}}(p_{_{j+1}}^{2}) -
       \pi_{_{2}}(p_{_{j}}^{2})) = \pi_{_{2}}(p_{_{k+1}}^{2})
       \approx \sum_{j=1}^{k} (p_{_{j+1}}^{2} -
       p_{_{j}}^{2})\prod_{i=2}^{j}(1 - \frac{2}{p_{_{i}}})
       \rightarrow \infty .
       [731]Reply
       [732]18 July, 2016 at 11:07 pm
       Anonymous
       It seems natural to expect that a combination of sieve
       methods with the abc conjecture (which is sufficiently
       strong for many famous problems in additive number theory)
       should give some progress on the twin prime conjecture. Is
       it possible? (or perhaps a new version of the abc
       conjecture is needed for such a progress?)
       [733]Reply


       [734]19 July, 2016 at 9:03 am
       [735]Terence Tao
       The abc conjecture constrains the behaviour of numbers with
       many repeated prime factors (such as [736]powerful numbers
       or very [737]smooth numbers), since it is those numbers for
       which the radical is going to be small enough that the abc
       conjecture carries nontrivial content. This is why that
       conjecture is useful for problems such as Fermat’s last
       theorem. The twin prime conjecture, by contrast, seems to
       relate only to the behaviour of numbers with very few
       factors (i.e. primes and almost primes). So there does not
       appear to be any obvious mechanism in which the abc
       conjecture could be deployed to improve upon the known
       results on the twin prime conjecture.
       [738]Reply


   [739]23 August, 2016 at 4:50 pm

   Will Sawin

   I think in the function field case one can now get many twin
   primes and not just a few, using symmetry tricks. For fixed
   $q>104$, there are a large number of pairs of mimic irreducible
   polynomia of degree $n$ that differ by $1$, for all
   sufficiently large $n$ relatively prime to $q-1$. The point is
   that a pair of polynomials that differ by any constant can
   often by transformed into a pair that differ by $1$, so bounded
   gaps implies twin primes. See
   thm 1.4 which doesn’t state that there are many such pairs, but
   it follows from the argument.
   [741]Reply
       [742]23 August, 2016 at 10:53 pm
       Anonymous
       It would be interesting to see if there are also Zhang type
       (i.e. above 1/2 ) estimates for levels of distribution for
       such number (or function) fields and their dependence on
       some parameters of each particular field.
       [743]Reply


   [744]19 July, 2016 at 10:31 am

   [745]Lior Silberman


   Erratum (repeated): the second displayed equation after
   equation (3) is missing a factor of \log\frac{n}{d} in the
   summand.

   [Corrected, thanks – T.]
   [746]Reply


   [747]19 July, 2016 at 3:31 pm

   [748]primework123


   On the Proof Sketch of the famous Polignac Conjecture


   We should consider three laws which govern the general
   behaviour of all prime numbers or their distribution (placement
   and number) along the natural number line:

   Prime Work:

   (1) There are infinitely many more positive integers (even or
   odd) than there are prime numbers, or prime numbers have a zero
   density relative to the positive integers according to the
   Prime Number Theorem (PNT), and

   (2) prime numbers generate the positive even integers so
   efficiently that gaps between two consecutive prime numbers
   increase without bound.

   (3) Prime Parity Law (PPL):

   Pi(e = m*g = 1 + p_2n) = 2 * Pi(g = 1 + p_n) = 2n where Pi(*)
   is the prime counting function, and p_n > 2, p_2n are odd prime
   numbers; 2 < m ≤ 3;
   and as g goes to infinity, m goes to 2.

   From our understanding of the work of primes, we create an
   exceptional set, E, of consecutive odd prime numbers, p_n and
   p_n+1, whose prime gap, |p_n, p_n+1 | is some positive even
   integer, 2i. And we let P be the set of all odd prime numbers.

   For example we construct the exceptional set, E_i:

   E_i = {p_n, p_n+1 : p_n, p_n+1 ∈ P and |p_n – p_n+1| = 2i for
   any positive integer, i}.

   And if we assume 0 ≤ |E_i| < ∞, then we must have the following
   probability calculation:

   Prob( |p_n – p_n+1| = 2i | for all odd primes, p_n, p_n+1 ∉
   E_i) = 0.

   If we cannot verify this result, then we have a contradiction!
   And Polignac conjecture is true! :-) Bonne chance!

   Reference link:
   [751]Reply
       [752]26 July, 2016 at 5:34 pm
       [753]primework123
       Updated Link:
       proof_of_the_famous_and_important_Polignac_Conjecture
       [755]Reply
       [756]27 July, 2016 at 6:29 am
       [757]primework123
       (2) Prime numbers generate the positive even integers so
       efficiently that gaps between two consecutive prime numbers
       increase without bound if and only if the Goldbach
       Conjecture and the Polignac Conjecture are true.
       Reference link:
       proof_of_the_famous_and_important_Polignac_Conjecture
       [759]Reply


       [760]27 July, 2016 at 6:34 pm
       [761]primework123
       An update:
       primework123
       (2) Prime numbers generate the positive even integers so
       efficiently according to the Prime Number Theorem that gaps
       between two consecutive prime numbers increase without
       bound if and only if the Goldbach Conjecture and the
       Polignac Conjecture are true.
       Reference link:
       proof_of_the_famous_and_important_Polignac_Conjecture
       [763]Reply


       [764]28 July, 2016 at 7:21 am
       [765]primework123
       Hmm. For the sake of more clarity we should have:
       (2) … the gaps between two consecutive prime numbers
       increase in size without bound …
       [766]Reply


   [767]20 July, 2016 at 12:24 am

   Maths student

   Dear Prof. Tao,

   just as an idea: It would be kind of beneficial to a lot of
   people if the lectures you give would be available via the
   internet in the form of a video; for, this would allow for
   consuming mathematics while eating, something which I find
   rather difficult because I can’t keep my head in a fixed
   position, making it impossible to read the stuff on the screen
   (or alternatively, I have to enlarge stuff, but then it looks
   bad and one has to scroll all the time).

   It would be a great joy to see lectures of yours on topics that
   I have a chance of understanding!

   w/br
   [768]Reply


       [769]22 August, 2016 at 7:32 pm
       Anonymous
       A number of Prof. Tao’s lectures are on youtube.
       [770]Reply


   [771]26 July, 2016 at 2:20 pm

   [772]Gil Kalai


   Apropos the twin prime conjecture, are all the difficulties for
   showing infinitely many primes of gap two apply for any other
   showing infinitely many pairs of primes of gap 23,101
   (precisely) might be somehow easier?)
   [773]Reply


       [774]26 July, 2016 at 7:35 pm
       Anonymous
       Only even gaps (unlike 23,101) should be considered.
       [775]Reply
       [776]26 July, 2016 at 10:12 pm
       [777]Gil Kalai
       (pppps, Yes, I meant 23,102)
       [778]Reply


       [779]28 July, 2016 at 2:30 am
       Bhupinder Singh Anand
       “… is there a possibility that showing infinitely many
       pairs of primes of gap 23,102 (precisely) might be somehow
       easier?”
       1. On the contrary. Although the reasoning should, prima
       facie, be similar, estimating the number \pi_{_{2}}(x) of
       twin(2) primes \leq x non-heuristically as \sum_{_{n \leq
       x}}P(n).P(n+2) —where P(n) is the de facto probability that
       a given n is a prime—is obviously less complicated than
       estimating the number \pi_{_{23102}}(x) of twin(23,102)
       primes \leq x non-heuristically as \sum_{_{n \leq
       x}}P(n).C(n+2) \ldots C(n+23100).P(n+23102) , where C(n) is
       the de facto probability that a given n is composite.
       2. In the case of a twin(2) prime, one would define an
       integer n as a TW_{_{2}}(k) integer if, and only if,
       r_{p_{_{i}}}(n) \neq 0 and r_{p_{_{i}}}(n) \neq 2 for all 1
       \leq i \leq k , where 0 \leq r_{_{i}}(n) \leq i-1 is
       defined for all i \geq 0 by:
       n + r_{_{i}}(n) \equiv 0\ (mod\ i) .
       3. Note that if n is a TW_{_{2}}(k) integer, then both n
       and n+2 are not divisible by any of the first k primes
       \{p_{_{1}}, p_{_{2}}, \ldots, p_{_{k}}\} .
       4. The asymptotic density of TW_{_{2}}(k) integers over the
       set of natural numbers is then D(TW_{_{2}}(k)) =
       \prod_{i=2}^{k}(1 - \frac{2}{p_{_{i}}}) .
       5. Further, if p_{_{k}}^{2} \leq n \leq p_{_{k+1}}^{2} is a
       TW_{_{2}}(k) integer, then either both n and n+2 are
       primes, or n+2 = p_{_{k +1}}^{2} .
       6. If we define \pi_{_{TW_{_{2}}(k)}}(n) as the number of
       TW_{_{2}}(k) integers \leq n , the expected number of
       TW_{_{2}}(k) integers in any interval (a, b) is given—with
       a binomial standard deviation—by \pi_{_{TW_{_{2}}(k)}}(b) -
       \pi_{_{TW_{_{2}}(k)}}(a) \approx (b-a)\prod_{i=2}^{k}(1 -
       \frac{2}{p_{_{i}}}) .
       7. Since \pi_{_{TW_{_{2}}(k)}}(p_{_{k+1}}^{2}) -
       \pi_{_{TW_{_{2}}(k)}}(p_{_{k}}^{2}) is at most one less
       than the number of twin(2) primes in the interval
       (p_{_{k+1}}^{2} - p_{_{k}}^{2}) , it follows that:
       \pi_{_{TW_{_{2}}(k)}}(p_{_{k+1}}^{2}) -
       \pi_{_{TW_{_{2}}(k)}}(p_{_{k}}^{2}) + 1 \geq
       \pi_{_{2}}(p_{_{k+1}}^{2}) - \pi_{_{2}}(p_{_{k)}}^{2}) \geq
       \pi_{_{TW_{_{2}}(k)}}(p_{_{k+1}}^{2}) -
       \pi_{_{TW_{_{2}}(k)}}(p_{_{k}}^{2})
       8. Now, the expected number of TW_{_{2}}(k) integers in the
       interval (p_{_{k+1}}^{2} - p_{_{k}}^{2}) is given by:
       \pi_{_{TW_{_{2}}(k)}}(p_{_{k+1}}^{2}) -
       \pi_{_{TW_{_{2}}(k)}}(p_{_{k}}^{2}) \approx (p_{_{k+1}}^{2}
       - p_{_{k}}^{2})\prod_{i=2}^{k}(1 - \frac{2}{p_{_{i}}}) .
       9. We conclude that the number \pi_{_{2}}(p_{_{k+1}}^{2})
       of twin(2) primes \leq p_{_{k+1}}^{2} is given by the
       cumulative non-heuristic approximation:
       \sum_{j=1}^{k} (\pi_{_{2}}(p_{_{j+1}}^{2}) -
       \pi_{_{2}}(p_{_{j}}^{2})) = \pi_{_{2}}(p_{_{k+1}}^{2})
       \approx \sum_{j=1}^{k} (p_{_{j+1}}^{2} -
       p_{_{j}}^{2})\prod_{i=2}^{j}(1 - \frac{2}{p_{_{i}}})
       \rightarrow \infty .
       10. However, in the case of a twin(23,102) prime, in order
       to argue similarly one would need to define, and consider
       only, integers n > p_{_{11551}}^{^{2}} as TW_{_{23102}}(k)
       integers if, and only if, r_{p_{_{i}}}(n) \neq 0 and
       r_{p_{_{i}}}(n) \neq 23102 for all 1 \leq i \leq k , but
       with the added qualification that, for each 1 \leq j <
       11551 , we must have r_{p_{_{i}}}(n) =2.j for some 1 \leq i
       \leq k , where 0 \leq r_{_{i}}(n) \leq i-1 is defined for
       all i \geq 0 by:
       n + r_{_{i}}(n) \equiv 0\ (mod\ i) .
       [780]Reply
       [781]29 July, 2016 at 6:15 am
       [782]gowers
       The parity problem strikes again …
       [783]Reply


   [784]27 July, 2016 at 1:45 am

   Anonymous

   According to the Wikipedia article on Polignac’s conjecture,
   the first Hardy-Littlewood conjecture gives (for each even n )
   an explicit asymptotic estimate for the number of prime gaps of
   size n below x .
   This estimate implies that each odd prime factor q of n
   increases the conjectured density (of prime gaps of size n )
   compared to the density of twin primes by the factor
   (q-1)/(q-2) .
   Therefore any prime gap with many distinct odd prime factors
   seems to be more frequent (and perhaps easier for such a
   proof).
   [785]Reply


   [786]27 July, 2016 at 8:02 am

   [787]Gil Kalai


   My very vague intuition is also in this direction. So e.g. now
   that we know that there are infinitely many pairs of gap at
   most 600 maybe we can prove that there are infinitely many
   pairs of gap 600! (Here ! is “factorial”) But specifically I
   wonder also if the infamous obstructions for twin primes apply
   also for 600! gap.

   Here is another obvious question that maybe is not hopeless
   now: are there infinitely many consecutive primes p and q such
   that q-p is between 600 and 600! (Again, ! is factorial!)
   [788]Reply


       [789]27 July, 2016 at 8:25 am
       [790]poqv
       Yes the obstruction still applies. The “obstruction”
       otherwise known as the parity barrier is encapsulated in
       the following problem: A sieve is not able to show that n
       (n + 2) is infinitely often a product of two primes, and
       it’s not able to show that this is infinitely often a
       product of three primes. Showing either of these statements
       would break the parity barrier. However sieves can show
       that n (n + 2) is infinitely often the product of either
       two or three primes. To break through this barrier you need
       additional techniques that break the parity barrier (such
       as analytic input from bilinear forms). Now sieves are also
       able to show results of the type “at least one of the
       object in this finite set is prime (or other desirable
       property)”, but can’t tell you which element exactly, for
       example there are also results on Artin’s conjecture on
       primitive roots which say that out of any set of three
       non-squares at least one satisfies Artin’s conjecture.
       [791]Reply


       [792]30 July, 2016 at 12:01 am
       Bhupinder Singh Anand
       One way to avoid the ‘parity’ barrier when estimating prime
       counting functions may be to recognise the following,
       essentially different, instances that involve defining the
       probability of an integer:
       (i) The probability P_{_{1}}(p) of selecting an integer
       that has the property p from a given set S of integers;
       Example 1: If N is the set of natural numbers, what is the
       probability of selecting an integer n \in N that has the
       property of being a prime?
       Since we cannot define a precise ratio of primes to
       composites in N , but only an order of magnitude such as
       O(\frac{1}{log_{_{e}}n}) , the probability P_{_{1}}(p)
       \equiv P(n \in N\ is\ a\ prime) of selecting an integer
       that is a prime obviously cannot be defined in N .
       (ii) The probability P_{_{2}}(p) that an integer, in a
       given set S of integers, has the property p ;
       Example 2: If N+ is the set of positive integers, what is
       the probability that an integer n \in N+ is even? This is
       the basis for setting odds in games such as roulette; or
       for determining the probability of the spin state of a
       particle.
       Since the ratio of odd to even numbers in N+ is 1:1 , the
       probability P_{_{2}}(p) \equiv P(n \in N+\ is\ even) that
       an integer n \in N+ has the property of being even—which
       obviously cannot depend upon the probability P_{_{1}}(p)
       \equiv P(n \in N+\ is\ even) of selecting an integer n \in
       N+ that has the property of being even—must be \frac{1}{2}
       , even though \sum_{_{i = 1}}^{^{\infty}}P(i \in N+\ is\
       even) \neq 1 .
       (iii) The probability P_{_{3}}(p) of determining that a
       given integer n has the property p .
       Example 3: I give you a 5 -digit combination lock along
       with a 10 -digit integer n . The lock only opens if you set
       the combination to a proper factor of n which is greater
       than 1 . What is the probability that the first combination
       you try will open the lock. This is the basis for RSA
       encryption, which provides the cryptosystem used by many
       banks for securing their communications.
       By considering the behaviour of 0 \leq r_{_{i}}(n) \leq i-1
       , which is defined for all i \geq 0 by:
       n + r_{_{i}}(n) \equiv 0\ (mod\ i) ,
       appropriately, this example admits that, whether or not a
       prime p divides a given integer n , is indeed independent
       of whether or not a prime q \neq p divides n ; whence we
       have that P_{_{3}}(p) \equiv P(n\ is\ a\ prime) =
       \prod_{_{i = 1}}^{^{\pi(\sqrt{n})}}(1-\frac{1}{p_{_{i}}}) .
       Whilst the ‘parity’ barrier is encountered in the first
       case, the last appears to circumvent it if we define prime
       counting functions in terms of the residues r_{_{i}}(n) ,
       which are best expressed in a 2-dimensional representation
       of Eratosthenes Sieve.
       [793]Reply
       [794]30 July, 2016 at 3:19 am
       Anonymous
       It seems that like other famous problems (e.g. FLT or the
       Poincare conjecture) if there is a solution for the twin
       prime conjecture, it may follow as a particular case of a
       solution to a more general problem (whose formulation is
       still unknown!) which allows the use of additional (and
       perhaps more general) mathematical methods.
       [795]Reply


       [796]1 August, 2016 at 1:19 pm
       [797]primework123
       FYI: On A Simpler Proof of Fermat’s Last Theorem,
       impler_Proof_of_Fermat%27s_Last_Theorem
       [799]1 August, 2016 at 5:01 pm
       Bhupinder Singh Anand
       Well yes, in the sense that we can define a Generalised
       Prime Counting Function, \sum_{j = 1}^{n} \prod_{i =
       a}^{\pi(\sqrt{j})}(1 - \frac{b}{p_{_{i}}}) , which
       estimates the number of integers \leq n such that there are
       b values that cannot occur amongst the residues
       r_{p_{_{i}}}(n) for a \leq i \leq \pi(\sqrt{j}) , where 0
       \leq r_{_{i}}(n) \leq i-1 is defined for all i \geq 0 by:
       n + r_{_{i}}(n) \equiv 0\ (mod\ i)
       Thus b = 1 yields an estimate for the number \pi(n) of
       primes \leq n ; and b = 2 an estimate for the number of
       TW_{_{2}} integers \leq n , which approximates the number
       \pi_{_{2}}(n) of twin primes \leq n .
       Note that:
       \sum_{j = 1}^{n} \prod_{i = a}^{\pi(\sqrt{j})}(1 -
       \frac{b}{p_{_{i}}}) \rightarrow \infty as n \rightarrow
       \infty if p_{_{a}} > b \geq 1 .
       [800]2 August, 2016 at 10:27 am
       Bhupinder Singh Anand
       At a slightly deeper level, the ‘general’ result—which
       admits non-heuristic estimations of prime-counting
       functions such as \pi(n) , \pi_{_{2}}(n) , and even of
       Dirichlet primes in an arithmetical progression—is that the
       prime divisors of an integer are independent.
       The argument runs as follows:
       (a) The probability P(n+u \equiv\ 0\ (mod\ i)\ |\ n > i >
       1;\ i > u \geq 0) that the spin of an i -faced cryptex
       wheel—with faces numbered 0, 1, 2, \ldots, i-1 —will yield
       the value 0 \leq u \leq i-1 , is \frac{1}{i} by the
       probability model for such an event as definable over the
       probability space (0, 1, 2, \ldots, i-1) .
       (b) The probability P(n+u \equiv\ 0\ (mod\ i);\ n+v \equiv\
       0\ (mod\ j)) that the simultaneous spin of one i -faced
       cryptex wheel, and one j -faced cryptex wheel, will yield
       the values 0 \leq u \leq i-1 and 0 \leq v \leq j-1 ,
       respectively, is \frac{1}{i.j} by the probability model for
       such a simultaneous event as defined over the probability
       space \{(u, v): i > u \geq 0,\ j > v \geq 0\} .
       (c) If i and j are co-prime, the compound probability P(i\
       divides\ n;\ j\ divides\ n) of correctly determining that i
       divides n and j divides n from the simultaneous spin of one
       i -faced cryptex wheel and one j -faced cryptex wheel, is
       the product of the probability of correctly determining
       that i divides n from the spin of an i -faced cryptex
       wheel, and the probability of correctly determining that j
       divides n from the spin of a j -faced cryptex wheel.
       Reason: If i and j are co-prime, and n + r_{i.j}(n) \equiv
       0\ (mod\ i.j) , then the i.j integers r_{j}(n).i +
       r_{i}(n).j are all incongruent and form a complete system
       of residues. It follows that n = a.i —whence i divides n
       —and also n = b.j —whence j divides n —if, and only if
       r_{i}(n) = r_{j}(n) = r_{i.j}(n) = 0 .
       Note: The assumption that i and j be co-prime is necessary,
       since the above would not follow if i and j were not
       co-prime. For instance, let j=2i . The probability that the
       spin of an i -faced cryptex wheel will then yield 0 —and
       allow us to correctly conclude that i divides n —is
       \frac{1}{i} , and the probability that the spin of a j
       -faced cryptex wheel will then yield 0 —and allow us to
       correctly conclude that j divides n —is \frac{1}{j} ; but
       the probability of correctly determining both that i
       divides n , and that j divides n , from a simultaneous spin
       of the two cryptex wheels is \frac{1}{j} , and not
       \frac{1}{i.j} .
       (d) If p and q are two unequal primes, the probability of
       determining whether p divides n is thus independent of the
       probability of determining whether q divides n .
       The significance of (d) for non-heuristic estimation of
       prime-counting functions is that;
       (e) The non-heuristic expected number of ‘prime’
       combinations—i.e., where a 0 does not appear, and so the
       combination corresponds 1-1 to a prime \leq n —which occur
       in a set of n simultaneous spins of the \pi(\sqrt{n})
       cryptex wheels with p_{_{1}},\ p_{_{2}},\ \ldots,\
       p_{_{\pi(\sqrt{n})}} faces, respectively, is a
       non-heuristic estimate of the number \pi(n) of primes \leq
       n ; whence \pi(n) \approx n.\prod_{_{i =
       1}}^{^{\pi(\sqrt{n})}}(1-\frac{1}{p_{_{i}}}) \rightarrow
       \infty , with a binomial standard deviation.
       Moreover, even though we cannot define the probability
       P_{_{1}}(p) \equiv P(n \in N\ is\ a\ prime) of selecting an
       integer from the set N of all natural numbers that has the
       property of being prime, it follows that:
       (f) The non-heuristic probability that an integer n has the
       property of being a prime is \prod_{_{i =
       1}}^{^{\pi(\sqrt{n})}}(1-\frac{1}{p_{_{i}}}) .
       The wider significance of (d) is that it also allows
       computing the complexity of Integer Factorisation:
       (g) Since any given integer n is a prime if, and only if,
       it is not divisible by any prime p \leq \sqrt{n} , and
       since n may be the square of a prime, it follows that we
       necessarily require at least one logical operation for each
       prime p \leq \sqrt{n} in order to logically determine
       whether p is a prime divisor of n .
       (h) Since the number of such primes is of the order
       O(\frac{\sqrt{n}}{log_{e}\ n}) , and the prime divisors of
       an integer are mutually independent, the number of
       computations required by any deterministic algorithm that
       always computes a prime factor of n cannot be
       polynomial-time—i.e. of order O((log_{e}\ n)^{c}) for any c
       —in the length of the input n .


   [801]3 August, 2016 at 2:19 am

   Angel Perez

   Goldbach conjecture and twin primes

   This demonstration is performed based on the following: every
   even number divides into pairs of summands.

   ie: \forall(2n-x) + x = 2n ; with (x = 1,2,3,4,5.....n)

   Therefore:

   \forall(2n-x) = (2a;2a+1;p)

   in all (x) always we have prime numbers.

   Therefore if (x = p) and (x = p_{k} we have.

   2n - p = (2a; 2a+1;p)
   and
   2n - p_{k} = (p_{x}; 2b+1) ie that: (i) latex 2n – p = p_{k}$ ;
   conjecture is correct.

   But if we asume that (i) does not exist, then only will exist
   in all (2n) the following.

   2n - p = 2a +1
   2n - p_{k} = 2b +1

   For equal (2n) we have.

   (2a+1) + p = (2b+1) + p_{k}

   This equality is defined that.

   1- (2a+1) - (2b + 1) = p - p_{k}
   2(a-b) = p - p_{k} < 2n

   2- (2a+1) + p + (2b+1) + p_{k} = 2(2n)

   Therefore by (2) shows that.

   p + p_{k} = (2a+1) + (2b+1) = 2n

   Every even number have a couple of summands that are prime
   numbers. Goldbach's conjecture is true.

   FOR TWINS PRIMES.

   \forall(p + (p +2)) = 2n

   They are always in the expression.

   [2n - (n-1)] + (n-1) = 2n ; exist for \forall(n = par)

   $latex \textbf{And (n) it has infinite value, directely implies
   that there are infinitely many twin primes}.

   I am Angel, student of profesor Andri Lopez
   [802]Reply


       [803]3 August, 2016 at 1:03 pm
       Anonymous
       If true, this short proof must be from “the book” !
       [804]Reply


   [805]6 August, 2016 at 3:08 am

   Jhon Hard

   It is absolutely true. I hope that the professor Tao he gives
   us his valuation, as soon as possible.
   [806]Reply


   [807]11 August, 2016 at 8:25 am

   [808]MDC


   I was more interested in the sifting density had by [809]eye
   cue balls. The parity problem is kind of “odd” but even as well
   and your “idiosyncratic twist” with a “Fourier-analytic
   flavour” is predictable but leaves slit tongues in the mouth of
   my gift stalking horse. While undergraduates pay more and half
   of empirical studies are getting invalidated because people
   can’t learn elementary regression diagnostics from the math
   departments, I guess prime number theory is fine, as long as
   you keep the discontinuity-challenged away from Wall Street.
   But seriously, a trillion zeros and I start falling asleep.
   However, as Gil can attest, you guys are still making more
   progress than the quantum computer crowd doing exponential
   computations on a psi-ontic wave function. Zoom, bank, spill…
   clowns.
   [810]Reply


   [811]14 August, 2016 at 2:58 am

   Jeffrey Helkenberg

   I would like to suggest that the twin prime problem has been
   incorrectly addressed, and that to prove there are an infinite
   number of them requires thinking along different lines. For
   example, there are 9 classes of twin primes, given by Sloane’s
   A224855, A224856, A224859, A224854, A224860, A224862, A224864,
   A224865 and A224857. To prove that A224854 [Numbers n such that
   90*n+11 and 90*n+13 are twin prime] contains infinite n one
   must produce an algorithm capable of reducing a sequence m
   [0,1,2,3,4,5,6,7,8,9…] to a smaller sequence n [0,1,2,3,5,7,9…]
   in such a way the algorithm does not contain a state dependency
   (the algorithm does not rely in any way on terms from the
   output to generate further results). What I mean is that such
   an algorithm cannot have an internal reference, as we find with
   traditional sieves.

   There are 24 sequence generator functions required to produce a
   list n of twin primes beneath some given limit. I will not
   attempt to reproduce those generator functions here, rather I
   will reference you to some code. I am not a mathematician, I am
   an algorithm designer. As such, I cannot express the content of
   my algorithms in “your” language. I know that you will
   instantly see the relationships and will immediately understand
   the implications of this work.

   There is one other sequence that is germane to this discussion,
   one that I feel will be far more illustrative that the twin
   prime sequence. Please refer to A255491 for a better
   understanding of the sieve referenced in the following link.

   [813]Reply


   [814]22 August, 2016 at 2:28 pm

   Romain Viguier

   Well done!
   [815]Reply


   [816]24 August, 2016 at 8:10 am

   Jeffrey Helkenberg

   Imagine listening to Beethoven’s 5th Symphony and then trying
   to write music for a single instrument to recreate what you
   heard. I feel that most attempts at making sense of the prime
   distribution amounts to little more than that, to wit, “That
   dog won’t hunt.” It is a valid approach to separate the twin
   prime conjecture into 9 separate problems, as the twin primes
   demonstrably reduce to 9 separate sequences. And as with
   reverse-engineering a symphony, it gets a lot easier to make
   sense of things once you realize there is more than one
   instrument at work. The same is true of the prime distribution;
   with Eratosthenes we have sq.rt limit functions necessary to
   reduce a list of numbers to a list of primes. This tells us
   nothing about the prime distribution as an object unto itself,
   rather it tells us about the functions that are “discovered
   along the way.” Perhaps most importantly the SoE is not a
   method to generate primes it is a method to generate composites
   while leaving a residue of primes. Well if you segregate the
   primes into 24 classes distributing composites becomes trivial.
   So as not to confuse the issue, let’s remain in base-10 and
   look at sequence A142312. This sequence is a counterpart to
   A181732. Obviously, being a list of primes, we can state that
   it is non-trivial to generate. However, as opposed to SoE, it
   is “insanely trivial” to produce the list of composites. There
   is no base-10 composite sequence associated with A142312, but
   there is a composite sequence for A181732, namely A255491.
   Below I offer you an alternative sieve method for generating
   the base-10 equivalent to A255491. Now, I am no mathematician,
   but I think that this is a radical improvement over SoE in
   terms of having no internal references and therefore it allows
   for OoOE (unlike SoE which requires strictly sequential
   processing). Regarding the python code below you can of course
   change the limit to suit your curiosity. Note: The 24 classes
   reduce to digital root and last digit preserving sequences,
   indicating that simple algebraic relations underpin the
   allowable p*q relationships.

   limit = 1
   limit2 = 2

   var_19 = [19 + (90*x) for x in xrange(0, limit)]
   var_19a = [y * (19 + (90*z)) for y in var_19 for z in xrange(0,
   limit2)]
   print var_19a

   var_91 = [91 + (90*x) for x in xrange(0, limit)]
   var_91a = [y * (91 + (90*z)) for y in var_91 for z in xrange(0,
   limit2)]
   print var_91a

   var_37 = [37 + (90*x) for x in xrange(0, limit)]
   var_73 = [y * (73 + (90*z)) for y in var_37 for z in xrange(0,
   limit2)]

   var_73a = [73 + (90*x) for x in xrange(0, limit)]
   var_37a = [y * (37 + (90*z)) for y in var_73a for z in
   xrange(0, limit2)]

   print var_73
   print var_37a

   var_11 = [11 + (90*x) for x in xrange(0, limit)]
   var_41 = [y * (41 + (90*z)) for y in var_11 for z in xrange(0,
   limit2)]

   var_41a = [41 + (90*x) for x in xrange(0, limit)]
   var_11a = [y * (11 + (90*z)) for y in var_41a for z in
   xrange(0, limit2)]

   print var_41
   print var_11a

   var_47 = [47 + (90*x) for x in xrange(0, limit)]
   var_23 = [y * (23 + (90*z)) for y in var_47 for z in xrange(0,
   limit2)]

   var_23a = [23 + (90*x) for x in xrange(0, limit)]
   var_47a = [y * (47 + (90*z)) for y in var_23a for z in
   xrange(0, limit2)]

   print var_23
   print var_47a

   var_83 = [83 + (90*x) for x in xrange(0, limit)]
   var_77 = [y * (77 + (90*z)) for y in var_83 for z in xrange(0,
   limit2)]

   var_77a = [77 + (90*x) for x in xrange(0, limit)]
   var_83a = [y * (83 + (90*z)) for y in var_77a for z in
   xrange(0, limit2)]

   print var_77
   print var_83a

   var_13 = [13 + (90*x) for x in xrange(0, limit)]
   var_7 = [y * (7 + (90*z)) for y in var_13 for z in xrange(0,
   limit2)]

   var_7a = [7 + (90*x) for x in xrange(0, limit)]
   var_13a = [y * (13 + (90*z)) for y in var_7a for z in xrange(0,
   limit2)]

   print var_7
   print var_13a

   var_31 = [31 + (90*x) for x in xrange(0, limit)]
   var_61 = [y * (61 + (90*z)) for y in var_31 for z in xrange(0,
   limit2)]

   var_61a = [61 + (90*x) for x in xrange(0, limit)]
   var_31a = [y * (31 + (90*z)) for y in var_61a for z in
   xrange(0, limit2)]

   print var_61
   print var_31a

   var_49 = [49 + (90*x) for x in xrange(0, limit)]
   var_79 = [y * (79 + (90*z)) for y in var_49 for z in xrange(0,
   limit2)]

   var_79a = [79 + (90*x) for x in xrange(0, limit)]
   var_49a = [y * (49 + (90*z)) for y in var_79a for z in
   xrange(0, limit2)]

   print var_79
   print var_49a

   var_67 = [67 + (90*x) for x in xrange(0, limit)]
   var_43 = [y * (43 + (90*z)) for y in var_67 for z in xrange(0,
   limit2)]

   var_43a = [43 + (90*x) for x in xrange(0, limit)]
   var_67a = [y * (67 + (90*z)) for y in var_43a for z in
   xrange(0, limit2)]

   print var_43
   print var_67a

   var_17 = [17 + (90*x) for x in xrange(0, limit)]
   var_53 = [y * (53 + (90*z)) for y in var_17 for z in xrange(0,
   limit2)]

   var_53a = [53 + (90*x) for x in xrange(0, limit)]
   var_17a = [y * (17 + (90*z)) for y in var_53a for z in
   xrange(0, limit2)]

   print var_53
   print var_17a

   var_71 = [71 + (90*x) for x in xrange(0, limit)]
   var_71a = [y * (71 + (90*z)) for y in var_71 for z in xrange(0,
   limit2)]
   print var_71a

   var_89 = [89 + (90*x) for x in xrange(0, limit)]
   var_89a = [y * (89 + (90*z)) for y in var_89 for z in xrange(0,
   limit2)]
   print var_89a

   sys.exit(0)
   [817]Reply


       [818]26 August, 2016 at 2:45 am
       Jeffrey Helkenberg
       Left one of the functions out. You can add the mergedlist
       lines at the end of the script to make more sense of the
       output, in terms of generating a csv output file that can
       be easily sorted. Captures all the composites provided the
       ranges are adequate.
       var_29 = [29 + (90*x) for x in xrange(0, limit)]
       var_59 = [y * (59 + (90*z)) for y in var_29 for z in xrange
       (0, limit2)]
       print var_59
       mergedlist = list(set(var_59 + var_29a + var_19a + var_91a
       var_77 + var_83a + var_7 + var_13a + var_61 + var_31a +
       var_79 + var_49a + var_43 + var_67a + var_53 + var_17a +
       var_71a + var_89a))
       values = mergedlist
       thecsv = csv.writer(open(“composites.csv”, ‘wb’))
       for value in values:
       thecsv.writerow([value])
       [819]Reply



